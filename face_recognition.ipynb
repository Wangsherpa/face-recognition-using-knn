{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition using KNN\n",
    "### Data Collection:\n",
    "#### Phase-I:\n",
    "1. Write a Python Script that captures images from your webcam video stream\n",
    "2. Extract all Faces from the image frame (Using haarcascades)\n",
    "3. Store the face information into numpy arrays\n",
    "\n",
    "#### Phase-II:\n",
    "1. Read and show video stream, capture images\n",
    "2. Detect faces and show the bounding box\n",
    "3. Flatten the largest face image and save in a numpy array\n",
    "4. Repeat the above for multiple person to generate training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T07:34:06.369465Z",
     "start_time": "2020-07-18T07:33:05.441447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of the person: test\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "(40, 30000)\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    'haarcascades/haarcascade_frontalface_alt.xml')\n",
    "skip = 0\n",
    "face_data = []\n",
    "dataset_path = './data/'\n",
    "filename = input(\"Enter the name of the person: \")\n",
    "while True:\n",
    "    # capture the frame (photo)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == False:\n",
    "        continue\n",
    "\n",
    "    # Convert captured frame to gray scale (single colour channel)\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "    faces = sorted(faces, key=lambda f: f[2]*f[3], reverse=True)\n",
    "\n",
    "\n",
    "    # pick the last face (because it is the largest face according to area(f[2]*f[3]))\n",
    "    for face in faces[-1:]:\n",
    "        x, y, w, h = face\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "\n",
    "        # Extract ROI (Region of Interest)\n",
    "        offset = 10\n",
    "        face_section = frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section, (100, 100))\n",
    "\n",
    "        skip += 1\n",
    "        if skip % 10 == 0:\n",
    "            face_data.append(face_section)\n",
    "            print(len(face_data))\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Face Section\", face_section)\n",
    "\n",
    "    # Store every 10th face\n",
    "    key_pressed = cv2.waitKey(1) & 0xFF\n",
    "    # if user presses 'q' then break exit from the loop\n",
    "    if key_pressed == ord('q'):\n",
    "        break\n",
    "# Convert our face list array into a numpy array\n",
    "face_data = np.asarray(face_data)\n",
    "face_data = face_data.reshape((face_data.shape[0], -1))\n",
    "print(face_data.shape)\n",
    "\n",
    "# save this data into file system\n",
    "np.save(dataset_path+filename+'.npy', face_data)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognise faces using KNN\n",
    "\n",
    "### Steps:\n",
    "1. Read a video stream using opencv.\n",
    "2. Extract faces out of it.\n",
    "3. Load the training data (numpy arrays of all the persons).\n",
    "  - X - values are stored in the numpy arrays\n",
    "  - y - values we need to assign for each person\n",
    "4. Use KNN to find the prediction of face (ini)\n",
    "5. Map the predicted id to the name of the user\n",
    "6. Display the prediction on the screen - bounding box and name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T07:29:38.071209Z",
     "start_time": "2020-07-18T07:29:38.064191Z"
    }
   },
   "outputs": [],
   "source": [
    "# KNN implementation from scratch\n",
    "def distance(x1, x2):\n",
    "    return np.sqrt(sum((x1 - x2)**2))\n",
    "\n",
    "\n",
    "def knn(train, test, k=5):\n",
    "    # Empty list\n",
    "    dist = []\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get the vector and label\n",
    "        ix = train[i, :-1]\n",
    "        iy = train[i, -1]\n",
    "\n",
    "        # Compute the distance from test poing\n",
    "        d = distance(test, ix)\n",
    "        dist.append([d, iy])\n",
    "\n",
    "    # sort based on distance from test point\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = np.array(dk)[:, -1]\n",
    "\n",
    "    # Get frequencies of each label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "\n",
    "    # find the max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "\n",
    "    return output[0][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T07:38:19.547525Z",
     "start_time": "2020-07-18T07:36:35.041341Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# init camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Face Detection\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    \"haarcascades/haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "skip = 0\n",
    "dataset_path = './data/'\n",
    "\n",
    "face_data = []\n",
    "labels = []\n",
    "\n",
    "# labels for given file\n",
    "class_id = 0\n",
    "# mapping between id and name\n",
    "names = {}\n",
    "\n",
    "# Data Preparation\n",
    "for fx in os.listdir(dataset_path):\n",
    "    if fx.endswith('.npy'):\n",
    "        # create a mapping between class_id and name\n",
    "        names[class_id] = fx[:-4]\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "\n",
    "        # create labels for class\n",
    "        target = class_id * np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data, axis=0)\n",
    "face_labels = np.concatenate(labels, axis=0).reshape((-1, 1))\n",
    "\n",
    "train_set = np.concatenate((face_dataset, face_labels), axis=1)\n",
    "\n",
    "# Testing\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret is None:\n",
    "        continue\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "\n",
    "    for face in faces:\n",
    "        x, y, w, h = face\n",
    "\n",
    "        # Get the face ROI\n",
    "        offset = 10\n",
    "        face_section = frame[y-offset:y+h+offset, x-offset:x+w+offset]\n",
    "        face_section = cv2.resize(face_section, (100, 100))\n",
    "\n",
    "        # predicted label (out)\n",
    "        out = knn(train_set, face_section.flatten())\n",
    "\n",
    "        # Display the name and the rectangle around the face\n",
    "        pred_name = names[int(out)]\n",
    "        cv2.putText(frame, pred_name, (x, y-10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T06:34:18.559851Z",
     "start_time": "2020-07-18T06:34:18.428940Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "style.use('dark_background')\n",
    "\n",
    "a = np.arange(0, 20)\n",
    "b = a**2\n",
    "plt.plot(a, b)\n",
    "plt.title(\"This is not showing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-18T06:30:46.872796Z",
     "start_time": "2020-07-18T06:30:34.138578Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
